{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "3ced5ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import unicodedata\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "6206668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://prosportstransactions.com/basketball/Search/SearchResults.php?Player=trade+with&Team=&BeginDate=1977-01-01&EndDate=&PlayerMovementChkBx=yes&Submit=Search\"\n",
    "page = requests.get(URL)\n",
    "soup = BeautifulSoup(page.content, \"html5lib\")\n",
    "table = soup.find('table')\n",
    "rows = table.findChildren(['th', 'tr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "a7358857",
   "metadata": {},
   "outputs": [],
   "source": [
    "exempted_keys = set([\"2000-02-01_Magic_Nuggets\", \"2016-06-29_Magic_Pistons\", \"1996-12-04_Bucks_Suns\",\n",
    "                    \"2021-07-30_Bucks_Pacers\", \"2013-07-22_Grizzlies_Mavericks\", \"2000-02-09_Celtics_Raptors\",\n",
    "                    \"1983-11-12_76ers_Pistons\", \"1986-08-08_Bullets_Nets\", \"1987-10-11_Blazers_Warriors\",\n",
    "                    \"1987-10-14_Rockets_Warriors\", \"1989-06-27_Bulls_Sonics\", \"1992-06-01_Bucks_Lakers (date approximate)\",\n",
    "                     \"1992-06-01_Bucks (date approximate)_Lakers\", \"1997-05-27_Celtics_Heat\", \"2011-12-11_Lakers_Mavericks\"])\n",
    "nodes_to_revised = {\"• Marcus Banks (changed to Jumaine Jones on 2004-08-13)\": \"• Jumaine Jones\",\n",
    "                    \"• Bobcats agreed to select Jahidi White from Suns in expansion draft\": \"• rights to Jahidi White\",\n",
    "                    \" • Bobcats agreed to select Jahidi White from Suns in expansion draft\": \"• rights to Jahidi White\",\n",
    "                    \"• Bobcats agreed to select Predrag Drobnjak / Peja Drobnjak in expansion draft\": \"• rights to Peja Drobnjak\",\n",
    "                    \" • Bobcats agreed to select Predrag Drobnjak / Peja Drobnjak in expansion draft\": \"• rights to Peja Drobnjak\",\n",
    "                    \"• future draft considerations (?)\": \"• 0000 second round pick (?-?)\",\n",
    "                    \" • future draft considerations (?)\": \"• 0000 second round pick (?-?)\",\n",
    "                    \"• 2026 draft pick (first round protected top 4, else second round) (?-?)\": \"• 2026 draft pick (first round pick protected top 4, else second round) (?-?)\",\n",
    "                    \"• 2021 second round pick (#32-Jeremiah Robinson-Earl)\": \"• 2021 second round pick (#32-Jeremiah Robinson Earl)\",\n",
    "                    \" • 2021 second round pick (#32-Jeremiah Robinson-Earl)\": \"• 2021 second round pick (#32-Jeremiah Robinson Earl)\",\n",
    "                    \" • $100K\": \"• $100K cash\",\n",
    "                    \"• the rights to Sergio Llull\": \"• rights to Sergio Llull\",\n",
    "                    \"• 1982 second round pick (#42-Jeff Taylor (b. 1960-01-01))\": \"• 1982 second round pick (#42-Jeff Taylor)\",\n",
    "                    \" • 1985 first round pick (#24-Terry Porter (b. 1963-04-08))\": \"• 1985 first round pick (#24-Terry Porter)\",\n",
    "                    \"• 1985 first round pick (#24-Terry Porter (b. 1963-04-08))\": \"• 1985 first round pick (#24-Terry Porter)\",\n",
    "                    \"• 1987 conditional pick (second round if Thompson joins Bucks roster this season, else third round) (#41-Kannard Johnson)\": \"• 1987 conditional second round pick (second round if Thompson joins Bucks roster this season, else third round) (#41-Kannard Johnson)\",\n",
    "                    \"• Bucks option to swap 2010 first round picks (Bulls pick protected top 10) (#15-Larry Sanders (b. 1988-11-21))\":\"• Bucks option to swap 2010 first round picks (Bulls pick protected top 10) (#15-Larry Sanders)\",\n",
    "                    \"• 2000 second round pick (#34-Khalid El-Amin)\":\"• 2000 second round pick (#34-Khalid El Amin)\",\n",
    "                   \"• Hawks 1986 \\\"top\\\" pick (?-?)\": \"• Hawks 1986 first round pick (?-?)\",\n",
    "                   \"• player to be named later (Tom Barker / Tommy Barker on 1979-02-14)\": \"• Tommy Barker\",\n",
    "                   \"• player to be named later (Mark Radford on 08-30)\": \"• Mark Radford\",\n",
    "                   \" • rights to restricted free agent Mike Bratz\":\"• rights to Mike Bratz\",\n",
    "                    \"• player to be named later (Gus Gerard on 11-25)\":\"• Gus Gerard\",\n",
    "                    \"• 2019 second round pick (#46-Talen Horton-Tucker)\": \"• 2019 second round pick (#46-Talen Horton Tucker)\",\n",
    "                    \"• player to be named later (Darnell Hillman on 1977-04-11)\": \"• Darnell Hillman\",\n",
    "                    \" • rights to Wally Walker- later replaced by Bill Hanzlik\":\"• rights to Bill Hanzlik\",\n",
    "                    \" • rights to restricted free agent Coby Dietrick\":\"• rights to Coby Dietrick\",\n",
    "                    \"• Rockets right to match offer sheet on free agent Dirk Minniefield\": \"• rights to Dirk Minniefield\",\n",
    "                    \" • Sonics agreed to not select Dennis Scott with the 1990 #2 pick\": \"• rights to Dennis Scott\",\n",
    "                    \" • Nets agreed to not select Dennis Scott in 1990 draft\": \"• rights to Dennis Scott\",\n",
    "                    \"• Nets waived right to void trade if Seikaly did not report\": \" \",\n",
    "                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "a18c92ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_edges_csv(file, filename, columns, data):\n",
    "    df = pd.DataFrame([data], columns=columns)\n",
    "    file = pd.concat([file, df])\n",
    "    file.to_csv(filename, index=False)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "8678b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_str(data: str):\n",
    "    offset = 1 if data[0] == ' ' else 0\n",
    "    if \" cash\" in data or \"future considerations\" in data:\n",
    "        return[\"C\", \"None\"]\n",
    "    elif \"rights to\" in data:\n",
    "        return [\"RT \", data[12+offset:]]\n",
    "    elif \"exception\" in data:\n",
    "        return [\"EX \", \"None\"]\n",
    "    elif \"round pick\" in data or \"draft pick\" in data:\n",
    "        if \"#\" in data and '-' in data and \"?-?\" not in data and \"not exercised\" not in data:\n",
    "            return [\"RPC \", data[data.rfind('-')+1:-1]]\n",
    "        return [\"RP \", \"None\"]\n",
    "    elif \"first refusal\" in data:\n",
    "        return [\"FR \", \"None\"]\n",
    "    elif \"expansion draft\" in data:\n",
    "        return [\"EP \", \"None\"]\n",
    "    else:\n",
    "        if '•' in data:\n",
    "            return [\"PL \", data[data.index('•')+2:]]\n",
    "        return [\"UK \", \"None\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "10edcd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class node:\n",
    "    def __init__(self, team, date):\n",
    "        self.name = \"n/a\"\n",
    "        self.node_type = \"n/a\"\n",
    "        self.draft_details = \"n/a\"\n",
    "        self.team = team\n",
    "        self.date = date\n",
    "        self.isRightsorPick = False\n",
    "        self.isPlayer = False\n",
    "        \n",
    "    def classify_node(self, data: str):\n",
    "        \n",
    "        offset = 1 if data[0] == ' ' else 0\n",
    "            \n",
    "        if \" cash\" in data or \"considerations\" in data:\n",
    "            self.node_type = \"cash\"            \n",
    "        elif \"rights to\" in data:\n",
    "            self.name = data[12+offset:]\n",
    "            slash_index = self.name.rfind('/')\n",
    "            if slash_index != -1:\n",
    "                self.name = self.name[slash_index+2:]\n",
    "            self.node_type = \"rights\"\n",
    "            self.isRightsorPick = True           \n",
    "        elif \"exception\" in data or \"exemption\" in data:\n",
    "            self.node_type = \"exception\"            \n",
    "        elif \"round pick\" in data or \"draft pick\" in data:\n",
    "            if \"#\" in data and '-' in data and \"?-?\" not in data and \"not exercised\" not in data:\n",
    "                self.name =  data[data.rfind('-')+1:-1]\n",
    "                slash_index = self.name.rfind('/')\n",
    "                if slash_index != -1:\n",
    "                    self.name = self.name[slash_index+2:]\n",
    "                self.node_type = \"conveyed\"     \n",
    "                self.draft_details = data[data.index('•')+2:]\n",
    "                self.isRightsorPick = True\n",
    "            else:\n",
    "                self.node_type = \"unconveyed\"             \n",
    "                self.draft_details = data[data.index('•')+2:]\n",
    "                self.isRightsorPick = True\n",
    "        elif \"first refusal\" in data:\n",
    "            self.node_type = \"first refusal\"\n",
    "        elif \"expansion draft\" in data:\n",
    "            self.node_type = \"expansion draft\"\n",
    "        else:\n",
    "            if '•' in data:\n",
    "                self.name = data[data.index('•')+2:]\n",
    "                slash_index = self.name.rfind('/')\n",
    "                if slash_index != -1:\n",
    "                    self.name = self.name[slash_index+2:]\n",
    "                self.node_type = \"player\"\n",
    "                self.isPlayer = True\n",
    "            else:\n",
    "                self.node_type = \"undef\"\n",
    "    def print_data(self):\n",
    "        print(\"node data -------------------------\")\n",
    "        if self.name != \"n/a\":\n",
    "            print(\"name: \" +  self.name)\n",
    "        if self.node_type != \"n/a\":\n",
    "            print(\"node_type: \" +  self.node_type)\n",
    "        if self.draft_details != \"n/a\":\n",
    "            print(\"draft_details: \" +  self.draft_details)\n",
    "        print(\"team: \" +  self.team)\n",
    "        print(\"date: \" +  self.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "2210b9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_teams_from_trade(team:str, notes: str):\n",
    "    if notes[5] == \"t\":\n",
    "        return(([team, notes[16:-5]]))\n",
    "    elif notes[5] == \"3\":\n",
    "        #print(\"********3 Team Trade********\")\n",
    "        temp = notes.replace(\" \", \"\")\n",
    "        return(([team] + temp[19:-5].split(',')))\n",
    "    elif notes[5] == \"4\":\n",
    "        #print(\"********4 Team Trade********\")\n",
    "        temp = notes.replace(\" \", \"\")\n",
    "        return(([team] + temp[19:-5].split(',')))\n",
    "    elif notes[5] == \"5\":\n",
    "        #print(\"********5 Team Trade********\")\n",
    "        temp = notes.replace(\" \", \"\")\n",
    "        return(([team] + temp[19:-5].split(',')))\n",
    "    else:\n",
    "        #edge cases\n",
    "        after_trade_with = notes[re.search(r'\\b(trade)\\b', notes).start() + len('trade with '):]\n",
    "        if ' ' in after_trade_with:\n",
    "            return(([team, after_trade_with[:after_trade_with.index(' ')]]))\n",
    "        else:\n",
    "            return(([team, after_trade_with[:]])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "5d57924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_visited_key(date: str, teams: list):\n",
    "    temp = sorted(teams)\n",
    "    res = [date] + temp\n",
    "    return '_'.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "f8195eb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns=['Key', 'Date', 'From', 'To', 'Teams Involved', 'Player Trade', 'Rights/Pick Trade']\n",
    "edges = pd.DataFrame(columns=columns)\n",
    "edges.to_csv('edges.csv', index=False)\n",
    "ID = 0\n",
    "two_team_visited = set()\n",
    "many_team_visited = set()\n",
    "key_player_to_team = dict()\n",
    "name_to_edges = dict()\n",
    "edgekey_to_data = dict()\n",
    "edgekey_to_team_aquires = dict()\n",
    "is_first_row = True\n",
    "while URL != None:\n",
    "# for _ in range(1):\n",
    "    for row in rows:\n",
    "        if is_first_row:\n",
    "            is_first_row = False\n",
    "            continue\n",
    "        cells = row.findChildren('td')\n",
    "        date, team, acquired, relinq, notes = cells\n",
    "        team = str(team)[5:-5]\n",
    "        teams = get_teams_from_trade(team, str(notes))\n",
    "        date = str(date)[20:-5]\n",
    "        edge_key = [generate_visited_key(date, teams), None]\n",
    "        if edge_key[0] in exempted_keys:\n",
    "            continue\n",
    "        nodes = [None, None]\n",
    "        acquired_list = []\n",
    "        relinq_list = []\n",
    "        pl_involved = False\n",
    "        rp_involved = False\n",
    "        # Seperate two team and more than two team trades.\n",
    "        # We only need to visit the first of the two team trade row\n",
    "        if len(teams) == 2 and edge_key[0] not in two_team_visited:\n",
    "            two_team_visited.add(edge_key[0])\n",
    "            for (i, acq) in enumerate(acquired):\n",
    "                if acq and str(acq) != \"<br/>\" and not str(acq).isspace():\n",
    "                    if acq in nodes_to_revised:\n",
    "                        acq = nodes_to_revised[acq]\n",
    "                    nodes[0] = node(teams[0], date)\n",
    "                    nodes[0].classify_node(str(acq))\n",
    "                    if '•' not in acq:\n",
    "                        continue\n",
    "                    acquired_list += [unicodedata.normalize(\"NFKD\", acq[acq.index('•')+2:])]\n",
    "                    for rel in relinq:\n",
    "                        if rel in nodes_to_revised:\n",
    "                            rel = nodes_to_revised[rel]\n",
    "                        if rel and str(rel) != \"<br/>\" and not str(rel).isspace():\n",
    "                            nodes[1] = node(teams[1], date)\n",
    "                            nodes[1].classify_node(str(rel))\n",
    "                            if (i == (len(acquired)-1)):\n",
    "                                relinq_list += [unicodedata.normalize(\"NFKD\", rel[rel.index('•')+2:])]\n",
    "                            temp = [min(nodes[0].name, nodes[1].name) , max(nodes[0].name, nodes[1].name)]\n",
    "                            edge_key[1] = '+'.join(temp)\n",
    "                            \n",
    "                            if nodes[0].name != 'n/a' and nodes[1].name != 'n/a':\n",
    "                                EK = str('='.join(edge_key))\n",
    "                                pl_involved = nodes[0].isPlayer or nodes[1].isPlayer\n",
    "                                rp_involved = nodes[0].isRightsorPick or nodes[1].isRightsorPick\n",
    "                                edges = update_edges_csv(edges, 'edges.csv', columns, \n",
    "                                                         [EK, date, nodes[0].name, nodes[1].name, \n",
    "                                                          str(teams), pl_involved, rp_involved])\n",
    "                                name_to_edges[nodes[0].name] = name_to_edges.get(nodes[0].name, []) + [ID]\n",
    "                                name_to_edges[nodes[1].name] = name_to_edges.get(nodes[1].name, []) + [ID]\n",
    "                                ID += 1\n",
    "            if edge_key[0] not in edgekey_to_team_aquires:\n",
    "                edgekey_to_team_aquires[edge_key[0]] = []\n",
    "            edgekey_to_team_aquires[edge_key[0]].append([teams[0]+\" Aquire: \"] + acquired_list[:])\n",
    "            edgekey_to_team_aquires[edge_key[0]].append([teams[1]+\" Aquire: \"] + relinq_list[:])\n",
    "        elif len(teams) > 2:\n",
    "            data = [date, team, acquired, relinq, notes]\n",
    "            #Only create nodes and edges of >2 team trades once we know where each player is coming from\n",
    "            #Once we visit every one of the teams we have the suitable information\n",
    "            if edge_key[0] not in edgekey_to_data or len(edgekey_to_data[edge_key[0]]) < len(teams):\n",
    "                for acq in acquired:\n",
    "                    curr = (classify_str(str(acq)))                    \n",
    "                    if (curr[0] == 'PL ' or curr[0] == 'RPC ' or curr[0] == 'RT ') and curr[1] != 'None':\n",
    "                        key_player_to_team[(edge_key[0], curr[1])] = team\n",
    "                edgekey_to_data[edge_key[0]] = edgekey_to_data.get(edge_key[0], []) + [data]\n",
    "\n",
    "            if len(edgekey_to_data[edge_key[0]]) == len(teams):\n",
    "                teams = get_teams_from_trade(team, str(notes))\n",
    "                for date, team, acquired, relinq, notes in edgekey_to_data[edge_key[0]]:\n",
    "                    for acq in acquired:\n",
    "                        if acq and str(acq) != \"<br/>\" and not str(acq).isspace():\n",
    "                            if acq in nodes_to_revised:\n",
    "                                acq = nodes_to_revised[acq]\n",
    "                            nodes[0] = node(team, date)\n",
    "                            nodes[0].classify_node(str(acq))\n",
    "                            if '•' not in acq:\n",
    "                                continue\n",
    "                            acquired_list += [unicodedata.normalize(\"NFKD\", acq[acq.index('•')+2:])]\n",
    "                            for rel in relinq:\n",
    "                                if rel and str(rel) != \"<br/>\" and not str(rel).isspace():\n",
    "                                    if rel in nodes_to_revised:\n",
    "                                        rel = nodes_to_revised[rel]\n",
    "                                    nodes[1] = node(\"Unknown\", date)\n",
    "                                    nodes[1].classify_node(str(rel))\n",
    "                                       \n",
    "                                    if (edge_key[0], nodes[1].name) in key_player_to_team:\n",
    "                                        nodes[1].team = key_player_to_team[(edge_key[0], nodes[1].name)]\n",
    "                                    temp = [min(nodes[0].name, nodes[1].name) , max(nodes[0].name, nodes[1].name)]\n",
    "                                    edge_key[1] = '+'.join(temp)\n",
    "                                    EK = str('='.join(edge_key))\n",
    "                                    if nodes[0].name != \"n/a\" and nodes[1].name != \"n/a\" and (EK not in many_team_visited):\n",
    "                                        many_team_visited.add(EK)\n",
    "                                        pl_involved = nodes[0].isPlayer or nodes[1].isPlayer\n",
    "                                        rp_involved = nodes[0].isRightsorPick or nodes[1].isRightsorPick\n",
    "                                        edges = update_edges_csv(edges, 'edges.csv', columns, [EK, date, nodes[0].name, nodes[1].name, \n",
    "                                                                                               ','.join(teams), pl_involved, rp_involved])\n",
    "                                        name_to_edges[nodes[0].name] = name_to_edges.get(nodes[0].name, []) + [ID]\n",
    "                                        name_to_edges[nodes[1].name] = name_to_edges.get(nodes[1].name, []) + [ID]\n",
    "                                        ID += 1\n",
    "                    if edge_key[0] not in edgekey_to_team_aquires:\n",
    "                        edgekey_to_team_aquires[edge_key[0]] = []\n",
    "                    edgekey_to_team_aquires[edge_key[0]].append([team+\" Aquire: \"] + acquired_list[:])\n",
    "                    acquired_list = []\n",
    "    next_link = soup.find('div', class_='container').find_all('p')[-1].find('a')\n",
    "    if next_link: \n",
    "        sleep(4)\n",
    "        URL = \"https://prosportstransactions.com/basketball/Search/\"+next_link['href']\n",
    "        page = requests.get(URL)\n",
    "        soup = BeautifulSoup(page.content, \"html5lib\")\n",
    "        table = soup.find('table')\n",
    "        rows = table.findChildren(['th', 'tr'])\n",
    "        is_first_row = True\n",
    "    else:\n",
    "        URL = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "aa11fcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.DataFrame(columns=['Name', 'Edges'])\n",
    "for key in name_to_edges:\n",
    "    df = pd.DataFrame([[key, str(name_to_edges[key])[1:-1]]], columns=['Name', 'Edges'])\n",
    "    nodes_df = pd.concat([nodes_df, df])\n",
    "nodes_df.to_csv('nodes.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "93782af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df = pd.DataFrame()\n",
    "for key in edgekey_to_team_aquires:\n",
    "    temp = [';'.join(x) for x in edgekey_to_team_aquires[key]]\n",
    "    df = pd.DataFrame([[key]+ temp])\n",
    "    trades_df = pd.concat([trades_df, df])\n",
    "trades_df.to_csv('trades.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
